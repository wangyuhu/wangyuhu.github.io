---
layout: post
title: 8」聊天系统与问答机器人
---

*过犹不及，止于至善*

*Your follow means everything to me, hahaha, thanks!*

隔行如隔山，下面是大佬的博客，本篇博客参考了这三篇博文

[中文检索式问答机器人初探](https://zhuanlan.zhihu.com/p/61513395)

[构建聊天机器人小天1.0](https://blog.csdn.net/qq_38150441/article/details/97271677)

[基于seq2seq的中文聊天机器人](https://blog.csdn.net/daniellibin/article/details/102758726)

![](/images/chatbot1.png)

### 什么是FAQ呢？

简介：在智能客服的业务场景中，对于用户频繁会问到的业务知识类问题的自动解答（以下简称为FAQ）是一个非常关键的需求，可以说是智能客服最为核心的用户场景，基本上来说，就是用户使用智能客服系统，提问了一个业务知识的问题，系统需要在知识库里找到最合适的那一个答案，且一般来说，知识库都是人工事先编辑好的。

例子：比如10086的在线智能客服，用户提问“如何查询话费”，那系统可以自动给出一个对应的知识“请您向10086号码发送‘HF’短信，即可查询当前话费”
特点：

在这个场景中，知识的域是垂直封闭的，并不是开放的，只取决于开发这个智能客服的公司或者个人的需要支持的业务范围是多大。
由于是垂直领域，知识的变化并不会过于频繁，且知识库其实一般都是一个已经编辑好的库，一般由问题与答案这样的pair对组成，而不是那种很复杂的图结构或者关联表结构。如“如何查询话费”与“请您向10086号码发送 ‘HF’短信，即可查询当前话费”这样的一个文本pair对构成。一般来说pair对的数量都是几十到几百几千不等，不会特别大。

回答相对简单，不需要太多的推理和解析，只需要知道是知识库里的哪一个回答即可，某种程度上可以看做是一个匹配问题甚至是分类问题。

目前比较典型的做法就是：召回+排序

我们从模型的角度来分析：

用传统NLP模型捕捉词形、浅层语义信息 -- 做召回，缩小搜索空间
用深度模型捕捉句子结构、深层语义信息 -- 对召回的item做rank

#### 召回模型：

分词、词性修正：对词典做定制，比如“xxx”等词在本场景中应该是一个专有名词，需要修改这些词的分词和词性

去停用词：取常用停用词和语料中的一些高频词、保留“你、我”等一些在此场景中有实际意义、有区分度的代词等

相关性扩展：当搜索“XX漂亮”时应该也把“XX美丽”等词形上不同但语义相近的问题召回，可以人肉用近义词典做细粒度定制，或者用word2vec找距离相近的词，虽然严格上不是“近义词”、而是“相关词\关联词”，比如它认为“男人”和“女人”相近

转为BOW：把原问题转为高维稀疏词频向量

--用tfidf weight代替词频做为词袋中各词对应的value（问题比较短的情况下）

--用lsa\lda等映射到低维空间（问题比较长，且不在乎信息损失）

检索：当用户提问时，通过以上五个步骤把问题映射为一个高维稀疏向量，然后从问题库中召回与其cosin距离最近的n个问题

-- 问题： 若每次用户提问时都与知识库中几十万个高维稀疏向量中算cosin 是不现实的、时间复杂度不可接受

-- 解决方法： Locality Sensitive Hashing（LSH）这种hash可以把距离很近的数据以较高的概率映射成同一个hash值

-- 选择：
sklearn中的LSHForest，但它检索慢、recall 低;
Facebook research的pysparnn，但它也有个缺点：建index慢，好在建index是一次性的、建好后用cPickle持久化，以后用时load就好了

#### 语义模型：

encoder： 把各问题encode成低维向量
模型： Siamese LSTM + attention，APCNN等
相似度计算：dot，cosine等
目前存在的一些问题以及解决方案：

1. 词语多义性问题
导致问题：无法正确识别问题，导致答案召回准确率降低
场景：例如“中国银联”=“银联”，“中国农业银行”=“农行”
解决方法：构造词语对等列表或者词语相关性表
一、词义相同的两个词可以以较高的关联性进行识别，从而提高答案的准确性
二、词义较为相近的两个词关联，从而提高相近答案的输出（建议的形式输出，例如我们没有发现XXX的答案，建议查看YYY的答案），提高用户对于会话智能的认可

2. 不正常的用户输入问题
导致问题：影响问题识别
场景：很多用户是因为存在问题或者发生故障来寻找客服服务的，本身带有消极的情绪，例如愤怒、着急、失望等。因此句子输入可能会带有某些包含情感的词语，比 如：他妈的等
解决方法（提升用户体验）： 一、感知用户的情绪并给予安慰； 设置安慰词表
二、建立“情感”词表，替换原询问句
三、定期数据统计，跟踪出现用户失望的会话，并从设计和数据方面进行改善

3. 如何准确捕捉问的类型
导致问题：无法将用户意图正确分类，就无法将查询输入系统
场景：用户会问“为什么？”，“是什么？”，“怎么做？”以及这三个类型的引申词，如“如何？”等
解决方法：
一、先对用户意图进行大概的分类
二、”是什么？“之类的问题考虑转向KB-QA，”为什么“，”怎么做“转向FAQ

目前已经对召回模型进行了简单的实现，主要是基于词频特征的匹配，后期会加上语义模型进行改进以及用EMLO和BERT进行问答。

#### TF-IDF
TF-IDF（term frequency–inverse document frequency）是一种用于信息检索与数据挖掘的常用加权技术。TF是词频(Term Frequency)，IDF是逆文本频率指数(Inverse Document Frequency)。

TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。TF-IDF加权的各种形式常被搜索引擎应用，作为文件与用户查询之间相关程度的度量或评级。除了TF-IDF以外，因特网上的搜索引擎还会使用基于链接分析的评级方法，以确定文件在搜寻结果中出现的顺序。

